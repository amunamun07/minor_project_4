{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-idf_similarity_score.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5-LD8nbEy8K",
        "outputId": "93f178f8-539d-4880-f298-d00c5b097987"
      },
      "source": [
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAOB_9jREt-_"
      },
      "source": [
        "\n",
        "def create_dict(sentences: list):\n",
        "  '''\n",
        "  function: to create dictionary (a bag of words) where keys:unique words and values:frequency(words)\n",
        "  parameters:\n",
        "  sentence: a list of 2 user input sentences\n",
        "  '''\n",
        "  dic = {}\n",
        "  for sentence in sentences:\n",
        "      sentence= sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "      words= word_tokenize(sentence.lower())\n",
        "      filtered_sentence = [w for w in words if not w in stop_words]\n",
        "      for word in filtered_sentence:\n",
        "          if(word in dic.keys()):\n",
        "              dic[word] = dic[word] +1\n",
        "          else:\n",
        "              dic[word] =1 \n",
        "  return dic\n",
        "\n",
        "\n",
        "def tfidf_cosine_similarity(sentences):\n",
        "  '''\n",
        "  function: to compute the cosine similarity score between any two sentences\n",
        "  parameters:\n",
        "  sentence: a list of 2 user input sentences\n",
        "  '''\n",
        "  bow_dic = create_dict(sentences)\n",
        "  #Compute sentence term matrix as well idf for each term \n",
        "  sentence_tf_matrix = np.zeros((len(sentences),len(bow_dic)))\n",
        "  sentence_idf_matrix = np.zeros((len(bow_dic),len(sentences)))\n",
        "  sentence_term_df = pd.DataFrame(sentence_tf_matrix ,columns=sorted(bow_dic.keys()))\n",
        "  sentence_count=0\n",
        "  sentence_list=[]\n",
        "  for sentence in sentences:\n",
        "      sentence= sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "      words= word_tokenize(sentence.lower())\n",
        "      for word in words:\n",
        "          if(word in bow_dic.keys()):\n",
        "            sentence_term_df[word][sentence_count] = sentence_term_df[word][sentence_count] +1     \n",
        "      sentence_count = sentence_count +1\n",
        "      sentence_list.append('sentence {}'.format(sentence_count))\n",
        "\n",
        "  #Computed idf for each word in vocab\n",
        "  idf_dict={}\n",
        "  for column in sentence_term_df.columns:\n",
        "      idf_dict[column]= np.log((len(sentences) +1 )/(1+ (sentence_term_df[column] != 0).sum()))+1\n",
        "\n",
        "      \n",
        "  #compute tf.idf matrix\n",
        "  sentence_tfidf_matrix = np.zeros((len(sentences),len(bow_dic)))\n",
        "  sentence_tfidf_df = pd.DataFrame(sentence_tfidf_matrix,index=sorted(sentence_list) ,columns=sorted(bow_dic.keys()))\n",
        "\n",
        "  sentence_count = 0\n",
        "  for sentence in sentences:\n",
        "      for key in idf_dict.keys():\n",
        "          sentence_tfidf_df[key][sentence_count] = sentence_term_df[key][sentence_count] * idf_dict[key]\n",
        "      sentence_count = sentence_count +1\n",
        "  # lets create a cosine similarity as a dataframe\n",
        "  cosine_sim = cosine_similarity(sentence_tfidf_df,sentence_tfidf_df)\n",
        "  cosine_sim_df = pd.DataFrame(cosine_sim,index=sorted(sentence_list),columns=sorted(sentence_list))\n",
        "  return cosine_sim_df"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNhrn08mFjOf",
        "outputId": "b2f20f13-e130-4da8-aabd-6c61df4ed9a0"
      },
      "source": [
        "sentences_list= ['Drinking water, is great for health','water resources has been degraded lately',\n",
        "                 'nowadays, it is had to get safe drinking water', 'play games and have fun.']\n",
        "\n",
        "print(tfidf_cosine_similarity(sentences_list))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            sentence 1  sentence 2  sentence 3  sentence 4\n",
            "sentence 1    1.000000    0.126815    0.294556         0.0\n",
            "sentence 2    0.126815    1.000000    0.109957         0.0\n",
            "sentence 3    0.294556    0.109957    1.000000         0.0\n",
            "sentence 4    0.000000    0.000000    0.000000         1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}